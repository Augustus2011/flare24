{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from diffusers import UNet2DModel\n",
    "import tqdm\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),  # Adjust these values as needed\n",
    "])\n",
    "\n",
    "model = UNet2DModel(\n",
    "        sample_size=512,  # the target image resolution\n",
    "        in_channels=2,  # the number of input channels, 3 for RGB images\n",
    "        out_channels=1,  # the number of output channels\n",
    "        layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "        block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channes for each UNet block\n",
    "        down_block_types=( \n",
    "            \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "            \"DownBlock2D\",\n",
    "            \"DownBlock2D\", \n",
    "            \"DownBlock2D\", \n",
    "            \"AttnDownBlock2D\",\n",
    "            \"DownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        ), \n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "            \"AttnUpBlock2D\", # a ResNet upsampling block with spatial self-attention \n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\", \n",
    "            \"UpBlock2D\"\n",
    "          ),\n",
    "    )\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/mnt/ai_neuro/august_kun/miccai/ContourDiff/data/domain_2/images/Case_00001_0000_slice000.png'\n",
    "image = Image.open(image_path).convert('L')\n",
    "\n",
    "\n",
    "image_tensor = preprocess(image)\n",
    "image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "if image_tensor.shape[1] == 1:\n",
    "    image_tensor = image_tensor.repeat(1, 2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 512, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "image_tensor = image_tensor.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor,0).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = F.cosine_similarity(encoded_image1_flat.unsqueeze(0), encoded_image2_flat.unsqueeze(0))\n",
    "\n",
    "print(f\"Cosine similarity: {cosine_similarity.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
